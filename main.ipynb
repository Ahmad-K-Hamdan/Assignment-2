{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "377bca6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b74211be",
   "metadata": {},
   "source": [
    "# Part 1 ‚Äî Non-Linear Regression\n",
    "\n",
    "In this section, we study the behavior of polynomial regression and ridge regularization when fitting a non-linear function.  \n",
    "We will examine how different values of the regularization parameter Œª affect model generalization, especially under a Leave-One-Out Cross-Validation (LOOCV) evaluation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5842c46",
   "metadata": {},
   "source": [
    "### Generating the Dataset\n",
    "\n",
    "We generate **25 data points** using the function:\n",
    "\n",
    "\\[\n",
    "y = sin(5 ùúã xi) + ùúÄ!\n",
    "\\]\n",
    "\n",
    "where:\n",
    "- \\( x  ‚àà (0, 1) \\)\n",
    "- \\( ùúÄ! ‚àà (-0.3, 0.3) \\)\n",
    "\n",
    "We then build polynomial features up to degree 9, producing:\n",
    "\n",
    "\\[\n",
    "X = [1, x, x^2, ..., x^9]\n",
    "\\]\n",
    "\n",
    "Finally, we hold out **5 points** as a final **test set**, leaving **20 points** for cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3f6639d",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(12)\n",
    "\n",
    "n = 25\n",
    "degree = 9\n",
    "\n",
    "x = np.random.rand(n)  \n",
    "eps = np.random.uniform(-0.3, 0.3, n)\n",
    "\n",
    "y = np.sin(5 * np.pi * x) + eps\n",
    "X = np.column_stack([x**k for k in range(degree + 1)])\n",
    "\n",
    "X_temp, X_test, y_temp, y_test, x_temp, x_test = train_test_split(\n",
    "    X, y, x, test_size=5, random_state=2)\n",
    "\n",
    "X_temp.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdcd8088",
   "metadata": {},
   "source": [
    "### Leave-One-Out Cross-Validation (LOOCV)\n",
    "\n",
    "Since our dataset is very small, using a traditional train/validation split would be unreliable.  \n",
    "Instead, for each value of Œª, we perform LOOCV on the 20 non-test points:\n",
    "\n",
    "1. Leave out one point for validation  \n",
    "2. Train on the remaining 19  \n",
    "3. Compute the squared error on the held-out point  \n",
    "4. Repeat for all 20 points  \n",
    "5. Average the validation errors to obtain the LOOCV error for that Œª  \n",
    "\n",
    "This process provides a more stable and unbiased estimate of model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4cf1242",
   "metadata": {},
   "outputs": [],
   "source": [
    "lambdas = [0, 0.01, 0.1, 1, 10]\n",
    "cv_errors = {}\n",
    "\n",
    "X_cv = X_temp\n",
    "y_cv = y_temp\n",
    "x_cv = x_temp\n",
    "\n",
    "for lam in lambdas:\n",
    "    errors = []\n",
    "\n",
    "    for i in range(len(X_cv)):\n",
    "        X_train = np.delete(X_cv, i, axis=0)\n",
    "        y_train = np.delete(y_cv, i, axis=0)\n",
    "\n",
    "        X_val = X_cv[i].reshape(1, -1)\n",
    "        y_val = y_cv[i]\n",
    "\n",
    "        model = Ridge(alpha=lam, fit_intercept=False)\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        y_pred = model.predict(X_val)\n",
    "        errors.append((y_val - y_pred[0])**2)\n",
    "\n",
    "    cv_errors[lam] = np.mean(errors)\n",
    "\n",
    "cv_errors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97b24950",
   "metadata": {},
   "source": [
    "### Selecting the Best Regularization Parameter Œª\n",
    "\n",
    "We compute CV_MSE for each tested value of Œª.  \n",
    "The Œª with the lowest LOOCV error is chosen as the **optimal regularization strength**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33138639",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_lambda = min(cv_errors, key=cv_errors.get)\n",
    "best_lambda"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed9a08e8",
   "metadata": {},
   "source": [
    "### Training the Final Model\n",
    "\n",
    "Using the best Œª from LOOCV, we refit the model on all 20 cross-validation points.  \n",
    "This gives the model the maximum amount of training data while still preserving an unbiased estimate of Œª."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03089159",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_model = Ridge(alpha=best_lambda, fit_intercept=False)\n",
    "final_model.fit(X_cv, y_cv)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83e2fc62",
   "metadata": {},
   "source": [
    "### Evaluating on the Test Set\n",
    "\n",
    "We now evaluate the chosen model on the 5 completely unseen test points.  \n",
    "This provides the **true generalization error** of our final model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e74b72ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_test = final_model.predict(X_test)\n",
    "test_mse = mean_squared_error(y_test, y_pred_test)\n",
    "test_mse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7d3b110",
   "metadata": {},
   "source": [
    "### Plotting the Polynomial Fits for Different Œª\n",
    "\n",
    "Here we visualize how the ridge regression model behaves for different Œª values.  \n",
    "- Small Œª ‚Üí flexible, wiggly curves (risk of overfitting)  \n",
    "- Large Œª ‚Üí smoother, more biased curves  \n",
    "\n",
    "The plot overlays:\n",
    "- The 20 LOOCV points (blue)\n",
    "- The 5 test points (red)\n",
    "- The fitted curves for each Œª\n",
    "\n",
    "This allows us to visually compare model smoothness and stability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8df5ff79",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,6))\n",
    "\n",
    "plt.scatter(x_cv, y_cv, color='blue', label='CV points (20)')\n",
    "plt.scatter(x_test, y_test, color='red', label='Test points (5)')\n",
    "\n",
    "grid = np.linspace(x.min(), x.max(), 600)\n",
    "X_grid = np.column_stack([grid**k for k in range(degree + 1)])\n",
    "\n",
    "for lam in lambdas:\n",
    "    model = Ridge(alpha=lam, fit_intercept=False)\n",
    "    model.fit(X_cv, y_cv)\n",
    "    y_pred_grid = model.predict(X_grid)\n",
    "    plt.plot(grid, y_pred_grid, label=f\"Œª = {lam}\")\n",
    "\n",
    "plt.title(\"Ridge Fits for Different Œª Values (LOOCV on 20 points)\")\n",
    "plt.xlabel(\"x\")\n",
    "plt.ylabel(\"y\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e854106d",
   "metadata": {},
   "source": [
    "### Summary of Results\n",
    "\n",
    "We print:\n",
    "\n",
    "- The LOOCV MSE for each Œª  \n",
    "- The selected best Œª  \n",
    "- The final test MSE  \n",
    "\n",
    "These values allow us to quantify:\n",
    "- How each Œª performed during cross-validation  \n",
    "- How well the chosen model generalizes to new data  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efe3f0dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"LOOCV Errors:\")\n",
    "for lam, err in cv_errors.items():\n",
    "    print(f\"lambda = {lam:<5}   CV MSE = {err:.6f}\")\n",
    "\n",
    "print(\"\\nBest lambda:\", best_lambda)\n",
    "print(\"Final Test MSE:\", test_mse)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
